"""Implementation for the environment to train the environmenet generator modle

The model is assumed to take the difficulty (generated by the teacher policy) and
generate a robot-environment abiding by the generated difficulty.

In this module, we implement the environment generator using reinforcement learninig,
for not constraining the creativity the model, i.e. there are numerous ways to generate
environments that abide by a certain difficulty.
"""
from typing import Tuple, Optional, Sequence, List
import logging
import os
import argparse
import threading
import random

from PIL import Image
import numpy as np
from gym import Env
from gym.envs.classic_control import rendering
import pyglet
from pyglet import gl
import pandas as pd
import torch
from torch.utils.data import Dataset, DataLoader
from torch.utils.tensorboard import SummaryWriter  # type: ignore
from torch import nn
from tqdm import tqdm

from highrl.obstacle.obstacles import Obstacles
from highrl.obstacle.single_obstacle import SingleObstacle
from highrl.agents.robot import Robot
from highrl.utils import Position
from highrl.utils.logger import init_logger
from highrl.configs import colors

_LOG = logging.getLogger(__name__)

HARD_OBS = 2
MED_OBS = 3
SMALL_OBS = 4
OBS_CNT = HARD_OBS + MED_OBS + SMALL_OBS
HARD_SIZE = 50
MED_SIZE = 40
SMALL_SIZE = 30
OUTPUT_SIZE = 4
ENV_SIZE = 256
MAX_DIFFICULTY = ENV_SIZE * ENV_SIZE
NUM_POINTS: int = OUTPUT_SIZE * (OBS_CNT + 1)
DEVICE = "cuda"
DATASET_COLLECTION = "env_gen"
ENV_GEN_WEIGHTS = "env_gen_weights.pth"
TEST_SIZE = 0.001
EVAL_POINTS = 5


class GeneratorEvalEnv(Env):
    """Evaluation Enviornment for the generator model"""

    def __init__(self, points: List[float]) -> None:
        super().__init__()
        self.robot, obstacles = self._convert_from_points_to_objects(points)
        self.robot.radius = 5
        self.robot.goal_radius = 2
        self.viewer = None
        (
            self.flat_contours,
            self.contours,
        ) = obstacles.get_flatten_contours()

    def _convert_from_points_to_objects(
        self,
        entries_points: List[float],
    ) -> Tuple[Robot, Obstacles]:
        """Convert from a list of floats representation to objects which are the robot and
        a list a of obstacles.
        """
        rob_x, rob_y, goal_x, goal_y = entries_points[:4]
        robot = Robot(Position[float](rob_x, rob_y), Position[float](goal_x, goal_y))
        obstacles_ls: List[SingleObstacle] = []
        for obs_j in range(4, NUM_POINTS, OUTPUT_SIZE):
            dims: List[int] = []
            for dim in range(OUTPUT_SIZE):
                dims.append(int(entries_points[obs_j + dim]))

            obstacles_ls.append(SingleObstacle(*dims))
        obstacles = Obstacles(obstacles_ls)
        return robot, obstacles

    def render(
        self,
        mode="human",
        save_path: Optional[str] = None,
    ) -> bool:
        """Renders robot and obstacles on an openGL window using gym viewer"""
        # Create viewer
        if self.viewer is None:
            self.viewer = rendering.Viewer(ENV_SIZE, ENV_SIZE)
            self.transform = rendering.Transform()
            self.transform.set_scale(10, 10)
            self.transform.set_translation(128, 128)
            self.transform = rendering.Transform()
            self.image_lock = threading.Lock()

        def make_circle(center: Tuple[float, float], radius: int, res=10) -> np.ndarray:
            """Create circle points

            Args:
                center (list): center of the circle
                radius (int): radius of the circle
                res (int, optional): resolution of points. Defaults to 10.

            Returns:
                list: vertices representing with desired resolution
            """
            thetas = np.linspace(0, 2 * np.pi, res + 1)[:-1]
            verts = np.zeros((res, 2))
            verts[:, 0] = center[0] + radius * np.cos(thetas)
            verts[:, 1] = center[1] + radius * np.sin(thetas)
            return verts

        with self.image_lock:
            self.viewer.draw_circle(r=10, color=(0.3, 0.3, 0.3))
            win = self.viewer.window
            win.switch_to()
            win.dispatch_events()
            win.clear()
            gl.glViewport(0, 0, ENV_SIZE, ENV_SIZE)
            # Green background
            gl.glBegin(gl.GL_QUADS)
            gl.glColor4f(*colors.bgcolor, 1.0)
            gl.glVertex3f(0, ENV_SIZE, 0)
            gl.glVertex3f(ENV_SIZE, ENV_SIZE, 0)
            gl.glVertex3f(ENV_SIZE, 0, 0)
            gl.glVertex3f(0, 0, 0)
            gl.glEnd()
            # Transform
            rob_x = self.robot.x_pos
            rob_y = self.robot.y_pos
            self.transform.enable()  # applies T_sim_in_viewport to below coords (all in sim frame)
            # Map closed obstacles ---
            for poly in self.contours:
                gl.glBegin(gl.GL_LINE_LOOP)
                gl.glColor4f(*colors.obstcolor, 1)
                for vert in poly:
                    gl.glVertex3f(vert[0], vert[1], 0)
                gl.glEnd()
            # Agent body
            for idx, agent in enumerate([self.robot]):
                agent_x = agent.x_pos
                agent_y = agent.y_pos
                angle = self.robot.fix(agent.theta + np.pi / 2, 2 * np.pi)
                agent_r = agent.radius
                # Agent as Circle
                poly = make_circle((agent_x, agent_y), agent_r)
                gl.glBegin(gl.GL_POLYGON)
                if idx == 0:
                    color = np.array([1.0, 1.0, 1.0])
                else:
                    color = colors.agentcolor
                gl.glColor4f(*color, 1)
                for vert in poly:
                    gl.glVertex3f(vert[0], vert[1], 0)
                gl.glEnd()
                # Direction triangle
                xnose = agent_x + agent_r * np.cos(angle)
                ynose = agent_y + agent_r * np.sin(angle)
                xright = agent_x + 0.3 * agent_r * -np.sin(angle)
                yright = agent_y + 0.3 * agent_r * np.cos(angle)
                xleft = agent_x - 0.3 * agent_r * -np.sin(angle)
                yleft = agent_y - 0.3 * agent_r * np.cos(angle)
                gl.glBegin(gl.GL_TRIANGLES)
                gl.glColor4f(*colors.nosecolor, 1)
                gl.glVertex3f(xnose, ynose, 0)
                gl.glVertex3f(xright, yright, 0)
                gl.glVertex3f(xleft, yleft, 0)
                gl.glEnd()
            # Goal
            xgoal = self.robot.gpos.x
            ygoal = self.robot.gpos.y
            rgoal = self.robot.goal_radius
            # Goal markers
            gl.glBegin(gl.GL_POLYGON)
            gl.glColor4f(*colors.goalcolor, 1)
            triangle = make_circle((xgoal, ygoal), rgoal)
            for vert in triangle:
                gl.glVertex3f(vert[0], vert[1], 0)
            gl.glEnd()
            # Goal line
            gl.glBegin(gl.GL_LINE_LOOP)
            gl.glColor4f(*colors.goallinecolor, 1)
            gl.glVertex3f(rob_x, rob_y, 0)
            gl.glVertex3f(xgoal, ygoal, 0)
            gl.glEnd()
            self.transform.disable()
            win.flip()
            if not save_path:
                return self.viewer.isopen

            pyglet.image.get_buffer_manager().get_color_buffer().save(save_path)
            self.viewer.close()
            return True

    def reset(self) -> dict:
        return {}

    def step(self, _) -> dict:
        return {}


class EnvGeneratorModelLSTM(nn.Module):
    """Enviroment generator model using LSTM seq2seq architecture"""

    teacher_forcing_ratio: float = 0.6

    def __init__(
        self,
        hidden_size: int,
        num_layers: int,
        use_sigmoid: bool = True,
    ) -> None:
        super().__init__()
        self.hidden_size = hidden_size
        self.num_layers = num_layers

        # This linear layer will be used to map from the hidden dimension
        # to the output dimension.
        self.out = nn.Linear(hidden_size, OUTPUT_SIZE)

        self.lstm = nn.LSTM(OUTPUT_SIZE, hidden_size, num_layers=num_layers)
        self.input = nn.Linear(1, OUTPUT_SIZE)
        self.use_sigmoid = use_sigmoid

    def _init_hidden(self, batch_size: int = 1) -> Tuple[torch.Tensor, torch.Tensor]:
        """Initialize the hidden and cell gate tensors for the LSTM layer"""
        return (
            torch.zeros(
                self.num_layers,
                batch_size,
                self.hidden_size,
                device=DEVICE,
            ),
            torch.zeros(
                self.num_layers,
                batch_size,
                self.hidden_size,
                device=DEVICE,
            ),
        )

    def forward(
        self,
        features: torch.Tensor,
        target: Optional[torch.Tensor] = None,
    ) -> torch.Tensor:
        """Forward pass through the actor network"""

        # Features dim = [batch_size, features_dim]

        # Here we are assuming that the model will build any environment
        # with 4 basic components: robot/goal, hard obstacles, medium obstacles,
        # and small obstacles.
        num_outputs = 1 + OBS_CNT
        outputs = []
        batch_size = features.size(0)
        hidden, cell = self._init_hidden(batch_size)
        sigmoid = nn.Sigmoid()

        # Repeating the difficulty value to match the output dimension
        # Output Dim = [batch_size, output_size]
        output = self.input(features)

        for idx in range(num_outputs):
            # Output Dim = [1, batch_size, hidden_size]
            output, (hidden, cell) = self.lstm(output.unsqueeze(0), (hidden, cell))

            # Dim = [batch_size, output_size]
            output = self.out(output.squeeze(0))

            # Running through sigmoid activation for output in range [0, 1]
            if self.use_sigmoid:
                output = sigmoid(output)

            if target and random.random() < self.teacher_forcing_ratio:
                output = target[:, idx * OUTPUT_SIZE : (idx + 1) * OUTPUT_SIZE]

            outputs.append(output)

        # Action dim = [batch_size, 4 * num_outputs]
        out_features = torch.concat(outputs, dim=1)

        if self.use_sigmoid:
            self.extend_obstacles_range(out_features)

        return out_features

    def _obstacle_conv(
        self,
        points: torch.Tensor,
        batch: int,
        offset: int,
        obs_cnt: int,
        obs_size: int,
    ) -> None:
        for idx in range(offset, offset + obs_cnt, 4):
            points[batch][idx] *= ENV_SIZE
            points[batch][idx + 1] *= ENV_SIZE
            points[batch][idx + 2] *= obs_size
            points[batch][idx + 3] *= obs_size

    def extend_obstacles_range(self, points: torch.Tensor) -> None:
        """Extend the range of the obstacles to the actual size of the
        environment.
        """
        batches = points.size(0)
        for batch in range(batches):
            j = 0
            self._obstacle_conv(points, batch, j, 4, ENV_SIZE)
            j += 4
            self._obstacle_conv(points, batch, j, j + HARD_OBS, HARD_SIZE)
            j += HARD_OBS
            self._obstacle_conv(points, batch, j, j + MED_OBS, MED_SIZE)
            j += MED_OBS
            self._obstacle_conv(points, batch, j, j + SMALL_OBS, SMALL_SIZE)


def collect_dataset(dataset_path: str = DATASET_COLLECTION) -> pd.DataFrame:
    """Collect dataset files stored in dataset_path directory into a single
    dataframe.
    """
    absolute_path = os.path.join(os.getcwd(), dataset_path)
    dataframe = pd.DataFrame()
    for file_name in os.listdir(absolute_path):
        file_path = os.path.join(absolute_path, file_name)
        if os.path.isdir(file_path):
            continue

        file_dataframe = pd.read_csv(file_path, index_col=0)
        dataframe = pd.concat([dataframe, file_dataframe])

    return dataframe


class EnvPointsDataset(Dataset):
    """Environment dataset implementation for pytorch dataset interface"""

    def __init__(self, dataset: pd.DataFrame) -> None:
        self.dataset = dataset

    def __len__(self) -> int:
        return len(self.dataset)

    def __getitem__(self, index: int) -> Tuple[torch.Tensor, torch.Tensor]:
        record = self.dataset.iloc[index]

        difficulty = record[-1]
        points = record[0:-1].to_numpy()

        return torch.Tensor([difficulty]), torch.Tensor(points)


class EarlyStoppingCallback:
    """Early stopping callback for training"""

    def __init__(self, patience: int = 10, delta: float = 10.0) -> None:
        self.patience = patience
        self.delta = delta
        self.best_loss = np.inf
        self.counter: int = 0
        self.early_stop = False

    def __call__(self, loss: torch.Tensor) -> bool:
        loss_val: float = loss.item()
        if loss_val < self.best_loss - self.delta:
            self.best_loss = loss_val
            self.counter = 0

        else:
            self.counter += 1
            if self.counter >= self.patience:
                self.early_stop = True

        return self.early_stop


def train_supervised(args: argparse.Namespace) -> None:
    """Main method for training the environment generator using supervised learning"""
    # num_test_steps = 5
    # test_each = 1000
    use_sigmoid = False

    _LOG.info("Initializing model")
    model = EnvGeneratorModelLSTM(args.hidden_size, args.num_layers, use_sigmoid)
    dataset_df = collect_dataset(args.dataset_path)
    dataset = EnvPointsDataset(dataset_df)
    dataloader = DataLoader(dataset, batch_size=args.batch_size, shuffle=True)
    model = model.to(DEVICE)
    optimizer = torch.optim.Adam(model.parameters(), args.learning_rate)
    total_steps = len(dataloader) * args.num_epochs
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
        optimizer,
        T_max=total_steps // 10000,
        eta_min=1e-6,
    )
    criterion = nn.MSELoss()
    tb_writer = SummaryWriter("runs")

    early_stopping = EarlyStoppingCallback(patience=10, delta=args.delta)
    step = 0
    stop = False
    _LOG.warning("You have %i datapoints", dataset_df.shape[0])
    _LOG.warning("Training started")
    for _ in range(args.num_epochs):
        for difficulty, points in tqdm(dataloader):
            optimizer.zero_grad()
            difficulty = difficulty.to(DEVICE)
            points = points.to(DEVICE)
            # pylint: disable=not-callable
            outputs = model(difficulty)
            loss = criterion(points, outputs)
            loss.backward()
            optimizer.step()
            tb_writer.add_scalar("Loss", loss.item(), step)
            if step % 1000 == 0:
                evaluate(dataset_df, model, step, tb_writer)

            if step % 10000 == 0:
                _LOG.info("Step [%i] Loss %f", step, loss.item())
                scheduler.step()

            if early_stopping(loss):
                _LOG.info("Early stopping at step %i", step)
                stop = True
                break

            step += 1

        if stop:
            break

    torch.save(model.state_dict(), ENV_GEN_WEIGHTS)


def evaluate(
    dataset_df: pd.DataFrame,
    model: nn.Module,
    step: int = 0,
    tb_writer: Optional[SummaryWriter] = None,
) -> None:
    """Evaluation for dataset points"""
    model.eval()
    num_points = dataset_df.shape[0]
    lower_bound = int(num_points - num_points * TEST_SIZE)
    upper_bound = num_points
    for point_idx in range(EVAL_POINTS):
        env_index = random.choice(range(lower_bound, upper_bound))
        record = dataset_df.iloc[env_index]
        difficulty = torch.tensor([record[-1]], dtype=torch.float32).to(DEVICE)
        difficulty = difficulty.unsqueeze(0)
        points: List[float] = record[:-1].to_list()

        def get_image(img_mark: str) -> str:
            return f"eval[{point_idx}-{step}]_{img_mark}.png"

        real_save_path = os.path.join(
            os.getcwd(),
            DATASET_COLLECTION,
            "eval",
            get_image("real"),
        )
        gen_save_path = os.path.join(
            os.getcwd(),
            DATASET_COLLECTION,
            "eval",
            get_image("gen"),
        )
        eval_env_real = GeneratorEvalEnv(points)
        eval_env_real.render(save_path=real_save_path)
        points: List[float] = model(difficulty)[0].tolist()
        eval_env_gen = GeneratorEvalEnv(points)
        eval_env_gen.render(save_path=gen_save_path)

        real_img = np.array(Image.open(real_save_path))
        real_img = real_img[:, :, :3]
        gen_img = np.array(Image.open(gen_save_path))
        gen_img = gen_img[:, :, :3]
        line = np.zeros((real_img.shape[0], 2, 3), dtype=np.uint8)
        combined = np.concatenate([real_img, line, gen_img], axis=1)
        combined = combined.transpose((2, 0, 1))

        assert tb_writer
        tb_writer.add_image(
            f"Eval [step={step}][{point_idx}-{EVAL_POINTS}]",
            combined,
            global_step=step,
        )

    model.train()


def main(argv: Optional[Sequence[str]] = None) -> None:
    """Main function for running the training script"""
    parser = argparse.ArgumentParser()
    parser.add_argument("-b", "--batch-size", default=64, type=int)
    parser.add_argument("-hz", "--hidden-size", default=16, type=int)
    parser.add_argument("-e", "--num-epochs", default=2, type=int)
    parser.add_argument("-d", "--dataset-path", default="env_gen", type=str)
    parser.add_argument("-lr", "--learning-rate", default=1e-3, type=float)
    parser.add_argument("-ly", "--num-layers", default=1, type=int)
    parser.add_argument("-dlt", "--delta", default=5.0, type=float)
    args = parser.parse_args(argv)

    train_supervised(args)


if __name__ == "__main__":
    init_logger()
    main()
